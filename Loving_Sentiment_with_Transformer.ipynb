{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Loving_Sentiment_with_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEctG7S+kixTxkXRAz103J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmachima/Is_this_love/blob/main/Loving_Sentiment_with_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jasmine Machima\n",
        "\n",
        "jasmine.machima@gmail.com\n",
        "\n",
        "A Transformer model for a sentiment analysis of Thai text segments on the subject of romantic relationships.\n",
        "\n"
      ],
      "metadata": {
        "id": "wImRBRXOY2cZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wgEmJXhilS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe97c59-24b1-4cb3-ba01-a846a1488880"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.display.max_rows = 9999\n",
        "import collections\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "print(\"TensorFlow version\",tf.__version__)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFLow version 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKSp8vPyk2pQ"
      },
      "source": [
        "# Set up for a TPU environment.\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AttaCut: A Fast and Accurate Neural Thai Word Segmenter**\n",
        "https://arxiv.org/ftp/arxiv/papers/1911/1911.07056.pdf\n",
        "\n",
        "by Pattarawat Chormai, Ponrawee Prasertsom, Attapol Rutherford.\n",
        "\n",
        "AttCut will be used to segment Thai alphabets into separate words. Word tokenization for the Thai language is not straightforward due to the fact that words are written without spacing between them. For example, 'ความรักเป็นเรื่องซับซ้อนและละเอียดละอ่อน', in Thai, is a whole sentence meaning 'Love is a complicated and delicate matter.'"
      ],
      "metadata": {
        "id": "cVAm6tnceRLf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsK9Fek7iUmD"
      },
      "source": [
        "!pip install attacut # Thai Word Segmenter \n",
        "# Most accurate Thai tokenizer so far\n",
        "from attacut import tokenize, Tokenizer\n",
        "atta = Tokenizer(model=\"attacut-c\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01yyKe2wa9Xe"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "# upload PantipLoveSentiments.csv and love_test.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset was manually curated from the popular Thai-language Pantip.com web forum, consisting of short text segments on the subject of romantic relationship experience. The set is divided into two classes of sentiments: positive or negative. "
      ],
      "metadata": {
        "id": "H7nopg8SLjdp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fmKp9gvKbPWm",
        "outputId": "1278fc01-19da-45b6-ac0b-0de9d5651cd5"
      },
      "source": [
        "bangrak = pd.read_csv('PantipLoveSentiments.csv')  # Mainly from the Bangrak board on Pantip\n",
        "love_test = pd.read_csv('love_test.csv')\n",
        "\n",
        "bangrak.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0759beb6-6343-4801-8796-a27c76273e77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>อาจเป็นเพราะเราเข้าใจกัน</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>พอมาถึงช่วงนึง เขาก็มีคนอื่นเข้ามาเพราะไปเที่ย...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>แฟนเราบอกว่า ทำไมไม่ให้ตังใช้บ้างเลย</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>เปรียบเราเป็นผู้หญิงที่สวยที่สุดสำหรับเขา</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ผมไปรุกหาคู่ชีวิตสร้างอนคตไปด้วยกัน</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0759beb6-6343-4801-8796-a27c76273e77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0759beb6-6343-4801-8796-a27c76273e77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0759beb6-6343-4801-8796-a27c76273e77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  category\n",
              "0                           อาจเป็นเพราะเราเข้าใจกัน  positive\n",
              "1  พอมาถึงช่วงนึง เขาก็มีคนอื่นเข้ามาเพราะไปเที่ย...  negative\n",
              "2               แฟนเราบอกว่า ทำไมไม่ให้ตังใช้บ้างเลย  negative\n",
              "3          เปรียบเราเป็นผู้หญิงที่สวยที่สุดสำหรับเขา  positive\n",
              "4                ผมไปรุกหาคู่ชีวิตสร้างอนคตไปด้วยกัน  positive"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all the \"words\" (group of successive characters) tokenized by the AttCut model.\n",
        "\n",
        "def token(Z):\n",
        "  Tokens = []  \n",
        "\n",
        "  for i in range(len(Z)):\n",
        "    token = atta.tokenize(Z[i])\n",
        "    Tokens.append(token)\n",
        "  return Tokens\n",
        "\n",
        "# Build vocabulary from both train/validation datasets and the separate test set.\n",
        "Tokens = token(bangrak['text'])\n",
        "Test_Tokens = token(love_test['text'])\n",
        "\n",
        "# Build the vocabulary list \"Words\"\n",
        "Words = []\n",
        "for  sentence in Tokens:\n",
        "  for word in sentence:\n",
        "    if word not in Words:\n",
        "      Words.append(word)\n",
        "    else:\n",
        "      pass\n",
        "for  sentence in Test_Tokens:\n",
        "  for word in sentence:\n",
        "    if word not in Words:\n",
        "      Words.append(word)\n",
        "    else:\n",
        "      pass\n"
      ],
      "metadata": {
        "id": "NXnXPNgz3Gos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRXfPBmRhGGc"
      },
      "source": [
        "class Thai_to_id():\n",
        "  def __init__(self, Vocab):\n",
        "    \n",
        "    self.Vocab = Vocab\n",
        "  \n",
        "  def convert_vocab_ids(self, items):\n",
        "    \n",
        "    vocab = collections.OrderedDict()\n",
        "    index = 3\n",
        "    \n",
        "    for  word in self.Vocab:\n",
        "        Token = str(word)\n",
        "        vocab[Token] = index\n",
        "        index += 1\n",
        "\n",
        "    output = [1] # Beginning of text\n",
        "    for item in items:\n",
        "        if item in vocab.keys():\n",
        "            output.append(vocab[item])\n",
        "        else:\n",
        "            output.append(3)  # 3 is designated \"unknown\"\n",
        "    output.append(2) # End of text\n",
        "\n",
        "    return output, vocab\n",
        "\n",
        "  def id_seq(self, tokens):\n",
        "  \n",
        "    IDs = []\n",
        "    exc = []\n",
        "    for i in range(len(tokens)):\n",
        "\n",
        "      token_id, v = self.convert_vocab_ids(tokens[i])\n",
        "      if len(tokens[i]) > 64:\n",
        "        print(len(tokens[i]),\"    \",(tokens[i]))\n",
        "        exc.append(i)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "      IDs.append(token_id)\n",
        "      \n",
        "    return IDs, exc\n",
        "\n",
        "thai_to_id = Thai_to_id(Vocab=Words)\n",
        "\n",
        "IDs,_ = thai_to_id.id_seq(Tokens)\n",
        "test_id, __ = thai_to_id.id_seq(Test_Tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl74psDbDkQm",
        "outputId": "d0bcb3e3-a7c9-46f9-bdc9-be5605b12a37"
      },
      "source": [
        "Class = set(bangrak['category'])  # List of unique categories\n",
        "CL = dict(zip(Class,list(range(2)))) # convert categories into numericals\n",
        "rvCL = dict(zip(list(range(2)),Class)) # reverse lookup for numerical label\n",
        "\n",
        "print(CL)\n",
        "\n",
        "def col_label(Table): \n",
        " \n",
        "  Table['Label'] = 0 # want integers only\n",
        "  \n",
        "  for i in Table.index:\n",
        "      Table.at[i,'Label'] = CL[Table.at[i,'category']]\n",
        "      \n",
        "  return Table\n",
        "\n",
        "data = col_label(bangrak)\n",
        "labels=np.array(data['Label'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'positive': 0, 'negative': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YtLiRh-269l"
      },
      "source": [
        "# Pad ids to the length of 64 with 0 for both train/validation and test datasets.\n",
        "\n",
        "Padded_IDs = np.array(tf.keras.preprocessing.sequence.pad_sequences(IDs, maxlen=64, dtype='int32', padding='post', value=0))\n",
        "test_IDs = tf.keras.preprocessing.sequence.pad_sequences(test_id, maxlen=64, dtype='int32', padding='post', value=0)\n",
        "\n",
        "train_inp,val_inp,train_label,val_label=train_test_split(Padded_IDs,labels,test_size=0.2, random_state=88)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_inp shape:',train_inp.shape)\n",
        "print('val_inp shape:',val_inp.shape)"
      ],
      "metadata": {
        "id": "ePVc4bcW5ckp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f5cbb6-0ece-4934-c2e7-4786e40b3ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_inp shape: (559, 64)\n",
            "val_inp shape: (140, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This basic Transformer model is built with elements from \"Transformer Model for Language Understanding\" at TensorFlow.org. The code below does NOT use any of the models available at TensorFlow Hub so that hyperparameters can be freely tuned."
      ],
      "metadata": {
        "id": "sDkJgfH1Kzso"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ab7e7c-af5a-4485-e653-1d53645a381a",
        "id": "CKJuwfMC2Nqt"
      },
      "source": [
        "with strategy.scope():\n",
        "  input_vocab_size = 1000\n",
        "  maximum_position_encoding = 1000\n",
        "  d_model = 1024\n",
        "  hidden_units = [2048, 1024]\n",
        "  rate = 0.1\n",
        "  dff = 2048\n",
        "  learning_rate = 7.2e-6\n",
        "  num_epochs = 22\n",
        "  batch_size = 64\n",
        "  num_heads = 8\n",
        "  transformer_layers = 12\n",
        "  num_classes = 2\n",
        "  seq_len = 64\n",
        "\n",
        "  def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "  def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                              np.arange(d_model)[np.newaxis, :],\n",
        "                              d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "  def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "    # add extra dimensions to add the padding to the attention logits.\n",
        "    return seq[:, tf.newaxis,tf.newaxis, :] # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "  \n",
        "  # Set up positional encoding and sequence-ids embedding\n",
        "  pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "  embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "\n",
        "  def emb_pos(x):\n",
        "    x = embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "    x += pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "  def dropout(rate):\n",
        "    return tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "      x = layers.Dense(units, activation=tf.nn.relu)(x)\n",
        "      x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "  class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "      super(MultiHeadAttention, self).__init__()\n",
        "      self.num_heads = num_heads\n",
        "      self.d_model = d_model\n",
        "\n",
        "      assert d_model % self.num_heads == 0\n",
        "\n",
        "      self.depth = d_model // self.num_heads\n",
        "\n",
        "      self.wq = tf.keras.layers.Dense(d_model)\n",
        "      self.wk = tf.keras.layers.Dense(d_model)\n",
        "      self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "      self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        " \n",
        "      x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth)) #Split the last dimension into (num_heads, depth).\n",
        "   \n",
        "      return tf.transpose(x, perm=[0, 2, 1, 3])   # to get (batch_size, num_heads, seq_len, depth)\n",
        "\n",
        "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
        "\n",
        "      matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "      # scale matmul_qk\n",
        "      dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "      scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "      \n",
        "      # add the mask to the scaled tensor.\n",
        "      if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "      # softmax step\n",
        "      attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  \n",
        "\n",
        "      output = tf.matmul(attention_weights, v)  \n",
        "\n",
        "      return output, attention_weights\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "      batch_size = tf.shape(q)[0]\n",
        "\n",
        "      q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "      k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "      v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "      q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "      k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "      v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "      # scaled_attention.shape = (batch_size, num_heads, seq_len_q, depth)\n",
        "      # attention_weights.shape = (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "      scaled_attention, attention_weights = self.scaled_dot_product_attention(q, k, v, mask)\n",
        "\n",
        "      scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "      concat_attention = tf.reshape(scaled_attention,\n",
        "                                    (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "      output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "      return output, attention_weights\n",
        "    \n",
        "  class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, batch_size, rate):\n",
        "      super(TransformerBlock, self).__init__()\n",
        "\n",
        "      self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "      self.layernorm1 = tf.keras.layers.LayerNormalization(axis = -1,epsilon=1e-7)\n",
        "      self.layernorm2 = tf.keras.layers.LayerNormalization(axis = -1,epsilon=1e-7)\n",
        "\n",
        "      self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "      self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "      self.dense1 = tf.keras.layers.Dense(dff, activation='relu')\n",
        "      self.dense2 =  tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def call(self, x, mask):\n",
        "      \n",
        "      attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "      attn_output = self.dropout1(attn_output, training=True)\n",
        "      attn_output = x + attn_output\n",
        "      out1 = self.layernorm1(attn_output)  \n",
        "\n",
        "      dns_output = self.dense1(out1)  \n",
        "      dns_output = self.dense2(dns_output)\n",
        "\n",
        "      dns_output = self.dropout2(dns_output, training=True)\n",
        "      out2 = self.layernorm2(out1 + dns_output)  \n",
        "      return out2\n",
        "\n",
        "  def classifier():\n",
        "\n",
        "    input = tf.keras.Input(shape=(seq_len, ),dtype=tf.float32, name='ID')\n",
        "    \n",
        "    x = emb_pos(input)\n",
        "    mask = create_padding_mask(input)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    TB = [TransformerBlock(d_model, num_heads, dff,batch_size, rate=0.0) \n",
        "                      for _ in range(transformer_layers)]\n",
        "\n",
        "    for i in range(transformer_layers):\n",
        "          \n",
        "        x = TB[i](x, mask)\n",
        "    \n",
        "    representation = layers.LayerNormalization(axis = -1, epsilon=1e-7)(x) \n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.1)(representation)  \n",
        "\n",
        "    features = mlp(representation, hidden_units=hidden_units, dropout_rate=0.1)  \n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "      \n",
        "    model = tf.keras.Model(inputs=input, outputs=logits)\n",
        "    return model\n",
        "\n",
        "  model = classifier()\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon = 1e-7)\n",
        "\n",
        "  model.compile(\n",
        "              optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"))\n",
        "             \n",
        "  history =  model.fit(x=train_inp,y=train_label, batch_size=batch_size,epochs=num_epochs, validation_data = (val_inp, val_label)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/22\n",
            "9/9 [==============================] - 142s 8s/step - loss: 1.7507 - accuracy: 0.4955 - val_loss: 0.8579 - val_accuracy: 0.4929\n",
            "Epoch 2/22\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.8946 - accuracy: 0.5349 - val_loss: 0.8006 - val_accuracy: 0.4929\n",
            "Epoch 3/22\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.8025 - accuracy: 0.5242 - val_loss: 0.6902 - val_accuracy: 0.4929\n",
            "Epoch 4/22\n",
            "9/9 [==============================] - 2s 211ms/step - loss: 0.7431 - accuracy: 0.5367 - val_loss: 0.7173 - val_accuracy: 0.5000\n",
            "Epoch 5/22\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.7091 - accuracy: 0.5957 - val_loss: 0.5814 - val_accuracy: 0.7000\n",
            "Epoch 6/22\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 0.5894 - accuracy: 0.6959 - val_loss: 0.5499 - val_accuracy: 0.7214\n",
            "Epoch 7/22\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.5442 - accuracy: 0.7442 - val_loss: 0.5259 - val_accuracy: 0.7143\n",
            "Epoch 8/22\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 0.4443 - accuracy: 0.8032 - val_loss: 0.5073 - val_accuracy: 0.7714\n",
            "Epoch 9/22\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.3816 - accuracy: 0.8408 - val_loss: 0.5419 - val_accuracy: 0.7929\n",
            "Epoch 10/22\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.2451 - accuracy: 0.8998 - val_loss: 0.5413 - val_accuracy: 0.7643\n",
            "Epoch 11/22\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.1494 - accuracy: 0.9535 - val_loss: 0.8770 - val_accuracy: 0.7500\n",
            "Epoch 12/22\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.1867 - accuracy: 0.9123 - val_loss: 0.7736 - val_accuracy: 0.7643\n",
            "Epoch 13/22\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.1087 - accuracy: 0.9499 - val_loss: 0.8177 - val_accuracy: 0.7929\n",
            "Epoch 14/22\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.0328 - accuracy: 0.9928 - val_loss: 0.8903 - val_accuracy: 0.7857\n",
            "Epoch 15/22\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.0405 - val_accuracy: 0.7643\n",
            "Epoch 16/22\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 1.1027 - val_accuracy: 0.7643\n",
            "Epoch 17/22\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1839 - val_accuracy: 0.7643\n",
            "Epoch 18/22\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.1992 - val_accuracy: 0.7643\n",
            "Epoch 19/22\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 6.0724e-04 - accuracy: 1.0000 - val_loss: 1.2309 - val_accuracy: 0.7786\n",
            "Epoch 20/22\n",
            "9/9 [==============================] - 2s 208ms/step - loss: 3.7027e-04 - accuracy: 1.0000 - val_loss: 1.2674 - val_accuracy: 0.7714\n",
            "Epoch 21/22\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 2.7433e-04 - accuracy: 1.0000 - val_loss: 1.2786 - val_accuracy: 0.7857\n",
            "Epoch 22/22\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 2.0965e-04 - accuracy: 1.0000 - val_loss: 1.2910 - val_accuracy: 0.7857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fonx11HqbeyR"
      },
      "source": [
        "# def to prepare a table with predicted category vs. true category\n",
        "\n",
        "def rev_label(pred, X,y_true):\n",
        "\n",
        "  predicted =[]\n",
        "  pred_cat = []\n",
        "  true_cat = []\n",
        "  for j in range(len(X)):\n",
        "    index= np.argmax(pred[j])\n",
        "    predicted.append(int(index))\n",
        "    cat = rvCL[index]\n",
        "    true = rvCL[y_true[j]]\n",
        "    pred_cat.append(cat)\n",
        "    true_cat.append(true)\n",
        "  return predicted, pred_cat, true_cat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x66Bgr20o5u"
      },
      "source": [
        "X_tr, X_ts, Y_tr, Y_ts=train_test_split(data['text'],data['Label'],test_size=0.2, random_state = 88)\n",
        "\n",
        "val_set = pd.DataFrame(X_ts)\n",
        "val_set['Label'] = Y_ts\n",
        "y_true = list(Y_ts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHRSfPhT1USR",
        "outputId": "61024fd3-41b7-4146-c69c-7393b9ada007"
      },
      "source": [
        "pred = model(val_inp)\n",
        "predicted, pred_cat, true_cat = rev_label(pred, X_ts, y_true)\n",
        "val_set['predicted'] = predicted\n",
        "val_set['true_cat'] = true_cat\n",
        "val_set['pred_cat'] = pred_cat\n",
        "\n",
        "print('number of wrong predictions:',len(val_set[val_set['Label']!=val_set['predicted']]))  \n",
        "wrong=val_set[val_set['Label']!=val_set['predicted']]  \n",
        "print('predicted negative while actually positive:',len(wrong[wrong['true_cat']=='positive']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of wrong predictions: 30\n",
            "predicted negative while actually positive: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "afczKrCDN7XK",
        "outputId": "3750bbea-9e6b-4508-f26b-cac9b3ccb127"
      },
      "source": [
        "wrong.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-287b77e4-fbe6-4029-9565-78c203dd279f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "      <th>predicted</th>\n",
              "      <th>true_cat</th>\n",
              "      <th>pred_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>642</th>\n",
              "      <td>จะกลับมาคบ แต่เราเองเป็นฝ่ายที่ไม่คบ</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>เราควรจัดการกับความรู้สึกแบบนี้ยังไงดีคะ</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>เราเป็นคนไม่ค่อยซีเรียส</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>เวลาคุยกับเราตะคอกด่าว่าเราสาระพัด</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>เราพยายามง้อสุดๆ</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-287b77e4-fbe6-4029-9565-78c203dd279f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-287b77e4-fbe6-4029-9565-78c203dd279f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-287b77e4-fbe6-4029-9565-78c203dd279f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         text  Label  ...  true_cat  pred_cat\n",
              "642      จะกลับมาคบ แต่เราเองเป็นฝ่ายที่ไม่คบ      1  ...  negative  positive\n",
              "429  เราควรจัดการกับความรู้สึกแบบนี้ยังไงดีคะ      1  ...  negative  positive\n",
              "356                   เราเป็นคนไม่ค่อยซีเรียส      0  ...  positive  negative\n",
              "529        เวลาคุยกับเราตะคอกด่าว่าเราสาระพัด      1  ...  negative  positive\n",
              "438                          เราพยายามง้อสุดๆ      0  ...  positive  negative\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zmO5unyx4hn",
        "outputId": "50a88f16-9847-4b8d-96b3-1eb9606664fd"
      },
      "source": [
        "l_test=col_label(pd.read_csv('love_test.csv'))  # Separate test dataset\n",
        "\n",
        "with strategy.scope():\n",
        "  test_pred = model(test_IDs)\n",
        "\n",
        "\n",
        "test_predicted, test_pred_cat, test_true_cat = rev_label(test_pred, l_test['text'], l_test['Label'])\n",
        "\n",
        "l_test['predicted'] = test_predicted\n",
        "l_test['pred_cat'] = test_pred_cat\n",
        "\n",
        "ACCU = sklearn.metrics.accuracy_score(l_test['Label'], l_test['predicted'], normalize=True, sample_weight=None)\n",
        "print('Test Accuracy =',round((ACCU*100),2),'%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy = 80.0 %\n"
          ]
        }
      ]
    }
  ]
}